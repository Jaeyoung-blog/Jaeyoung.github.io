<!DOCTYPE html>
<html lang="ko">

<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">

    
      <link rel="icon" href="/favicon.png">
    

    <title>
        
          KL Divergence - Jaeyoung&#39;s Blog
        
    </title>

    <!-- Spectre.css framework -->
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">

    <!-- theme css & js -->
    <link rel="stylesheet" href="/css/book.css">
    <script src="/js/book.js"></script>

    <!-- tocbot -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
    
    <!-- katex -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/zooming/2.1.1/zooming.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    const zooming = new Zooming()
    zooming.listen('.book-content img')
})
</script>

</head>

<body>

<div class="book-container">
  <div class="book-sidebar">
    <div class="book-brand">
  <a href="/">
    <img src="/favicon.png">
    <span>JAEYOUNG&#39;S BLOG</span>
  </a>
</div>
    <div class="book-menu">
  
</div>

<script src="/js/book-menu.js"></script>
  </div>

  <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
  <div class="sidebar-toggle-inner"></div>
</div>

<script>
function add_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.add('show')  
}

function remove_inner() {
  let inner = document.querySelector('.sidebar-toggle-inner')
  inner.classList.remove('show')
}

function sidebar_toggle() {
    let sidebar_toggle = document.querySelector('.sidebar-toggle')
    let sidebar = document.querySelector('.book-sidebar')
    let content = document.querySelector('.off-canvas-content')
    if (sidebar_toggle.classList.contains('extend')) { // show
        sidebar_toggle.classList.remove('extend')
        sidebar.classList.remove('hide')
        content.classList.remove('extend')
    }
    else { // hide
        sidebar_toggle.classList.add('extend')
        sidebar.classList.add('hide')
        content.classList.add('extend')
    }
}
</script>

  <div class="off-canvas-content">
    <div class="columns">
      <div class="column col-10 col-lg-12">
        <div class="book-navbar">
          <!-- For Responsive Layout -->

<header class="navbar">
  <section class="navbar-section">
    <a onclick="open_sidebar()">
      <i class="icon icon-menu"></i>
    </a>
  </section>
</header>

        </div>
        <div class="book-content">
          <div class="book-post">
  <h1>KL-Divergence</h1>
<p>KL-Divergence에는 두 가지가 있다.</p>
<ul>
<li>Forward KL-Divergence</li>
<li>Reverse KL-Divergence</li>
</ul>
<p>기본적으로 KL-divergence라고 하면 forward 방식을 가리키며, variational autoencoder에는 reverse방식을 사용한다.</p>
<h2 id="Forward-KL-Divergence">Forward KL-Divergence</h2>
<p>다음이 forward KL-divergence의 식이다.<br>
$$<br>
KLD(P||Q) = \sum_x P(x) \cdot log(\frac{P(x)}{Q(x)})<br>
$$<br>
KL-divergence는 두 확률분포 $P,Q$의 유사도를 나타낼 수 있다. 즉, $P,Q$가 서로 비슷한 모양으로 분포된 확률분포라면, KLD값은 낮다.</p>
<p>이 KL-divergence는 entropy와 관련이 있는데, entropy는 정보량의 기댓값으로, 정보량은 두 확률 사이의 차이가 크면 큰 값을 가진다. 즉, 확률값이 많이 다르면 entropy가 높다.</p>
<p>두 확률분포간 거리를 최소화하는게 목적이 아니라면, $P,Q$에 두 확률분포를 넣고 거리를 구하면 된다. 보통 $P$는 target, true 확률분포가 들어가고 $Q$에는 측정하고자 하는 대상이 들어간다.</p>
<p>두 확률분포간 거리를 최소화시키고자 할때는, $P(x)$는 target 확률 분포, 즉, 목표로 하는 확률분포이며, $Q(x)$는 최적화시키고자 하는 확률분포, 즉, 파라미터가 있는 확률분포이다. 그리고 KLD 식을 최소화하는 $Q(x)$를 수정한다. 즉, $P(x)$에 가깝게 $Q(x)$를 수정하게 된다.</p>
<h3 id="Forward-KLD의-특징">Forward KLD의 특징</h3>
<p>Forward KLD는 $P(x)&gt;0$인 모든 지점에 대해서 확률 분포간의 차이를 줄이려고 노력한다. 최적화된 결과, *<em>$P(x)&gt;$<em>를 만족하는 모든 $x$의 범위를 $Q(x)$가 커버하게 된다.</em></em></p>
<p>다만, 다음처럼, 최소화된 이후의 KLD 값은 상당히 클 수가 있다.</p>
<p><img src="https://raw.githubusercontent.com/wayexists02/my-study-note/image/typora/image/1569470523821.png" alt="1569470523821"></p>
<p>(그림 출처: <a href="https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/" target="_blank" rel="noopener">https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/</a>)</p>
<p>위의 경우, KLD를 최소화한 결과지만, 결과값도 상당히 큰 KLD값을 가진다. 왜냐하면, $P(x)&gt;0$인 전체 범위를 커버하려고 하기 때문에, $Q(x)$를 정확하게 모델링하지 않으면(위의 경우, 두 가우시안의 mixture model로 해야 할 것이다) 위와 같은 문제가 생긴다.</p>
<h2 id="Reverse-KL-Divergence">Reverse KL-Divergence</h2>
<p>다음이 Reverse KL-divergence의 식이다.<br>
$$<br>
RKLD(Q||P) = \sum_x Q(x) \cdot log(\frac{Q(x)}{P(x)})<br>
$$</p>
<h3 id="Reverse-KLD의-특징">Reverse KLD의 특징</h3>
<p>만약, 두 분포간의 거리를 측정하고자 하면, forward 방식과 별 다를게 없다. 다만, 값의 차이는 있다. KLD는 대칭함수가 아니기 때문이다.</p>
<p>하지만, 최소화하려고 할 경우, 이번엔 파라미터가 있는 $Q(x)$분포와 target 분포 $P(x)$의 자리가 바뀌었다. 이때는, $Q(x)$가 굳이 $P(x)&gt;0$를 만족하는 모든 $x$범위를 커버하려고 하지 않는다. 식에서 보면, $Q(x) \approx 0$으로 맞춰버리면 그 $x$범위는 최소화가 된다. 즉, 필요한 곳만 볼록 솟게 해서 그 범위에서 최소화를 시키고 나머지 봉우리는 $Q(x) \approx 0$으로 해버리므로, <strong>특정 부분만 캡쳐해서 분포간 거리를 최소화한다.</strong></p>
<p>따라서 다음 그림처럼 된다.</p>
<p><img src="https://raw.githubusercontent.com/wayexists02/my-study-note/image/typora/image/1569470891541.png" alt="1569470891541"></p>
<p>(그림 출처: <a href="https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/" target="_blank" rel="noopener">https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/</a>)</p>
<h2 id="어떤-KLD를-사용해야-할까">어떤 KLD를 사용해야 할까</h2>
<p>만약, 모델링한 $Q(x)$가 target 분포 $P(x)$와 매우 가깝다고 자신이 있을 경우, 또는 $P(x)&gt;0$인 모든 $x$를 커버해야 할 경우, forward KLD를 사용하자.</p>
<p>하지만, 모델링한 $Q(x)$가 target 분포 $P(x)$와 가깝다는 자신이 없고, 분포의 major한 부분만 캡쳐해도 좋은 경우, Reverse KLD를 사용하자.</p>
<h2 id="Reference">Reference</h2>
<p><a href="https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/" target="_blank" rel="noopener">https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/</a></p>

</div>


  <div class="book-comments">
    




  </div>


<script src="/js/book-post.js"></script>
        </div>
      </div>
      <div class="column col-2 hide-lg">
        <div class="book-post-info">
  
    <div class="book-post-meta">

  <div class="author">

    <!-- Author image -->
    <div class="author-img">
      
        <figure
          class="avatar avatar-lg"
          data-initial="L"
          style="background-color: #3b4351;">
        </figure>
      
    </div>

    <!-- Author title -->
    <div class="author-title">
      <div>Lee Jaeyoung</div>
      <div>2020-03-03</div>
    </div>
  </div>

  
    <div class="divider"></div>

    <div class="link">
      <a class="category-link" href="/categories/Study-Notes/">Study Notes</a> <a class="category-link" href="/categories/Study-Notes/Machine-Learning/">Machine Learning</a>

      <a class="tag-link" href="/tags/MachineLearning/">#MachineLearning</a> <a class="tag-link" href="/tags/StudyNotes/">#StudyNotes</a>
    </div>
    
  

  <div class="divider"></div>
</div>
  

  <div class="book-tocbot">
</div>
<div class="book-tocbot-menu">
  <a class="book-toc-expand" onclick="expand_toc()">Expand all</a>
  <a onclick="go_top()">Back to top</a>
  <a onclick="go_bottom()">Go to bottom</a>
</div>

<script src="/js/book-toc.js"></script>
</div>
      </div>
    </div>
  </div>
  
  <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
</div>

</body>
</html>

<script src="/js/book.js"></script>