<!DOCTYPE html>
<html lang="ko">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    
    <title>Hidden Markov Models 2 | Jaeyoung&#39;s Blog</title>
    
    
        <meta name="keywords" content="StudyNotes,MachineLearning">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Hidden Markov ModelsUdemy 강좌: https://www.udemy.com/course/unsupervised-machine-learning-hidden-markov-models-in-python Hidden Markov model(HMM)은 다음과 같이 maximum likelihood estimation을 이용해서 파라미터를 추정하게">
<meta name="keywords" content="StudyNotes,MachineLearning">
<meta property="og:type" content="article">
<meta property="og:title" content="Hidden Markov Models 2">
<meta property="og:url" content="https://jaeyoung-blog.github.io/wiki/studynotes/machine-learning/Hidden_Markov_Models-2/index.html">
<meta property="og:site_name" content="Jaeyoung&#39;s Blog">
<meta property="og:description" content="Hidden Markov ModelsUdemy 강좌: https://www.udemy.com/course/unsupervised-machine-learning-hidden-markov-models-in-python Hidden Markov model(HMM)은 다음과 같이 maximum likelihood estimation을 이용해서 파라미터를 추정하게">
<meta property="og:locale" content="ko">
<meta property="og:updated_time" content="2020-03-06T02:31:09.640Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hidden Markov Models 2">
<meta name="twitter:description" content="Hidden Markov ModelsUdemy 강좌: https://www.udemy.com/course/unsupervised-machine-learning-hidden-markov-models-in-python Hidden Markov model(HMM)은 다음과 같이 maximum likelihood estimation을 이용해서 파라미터를 추정하게">
    

    
        <link rel="alternate" href="/atom.xml" title="Jaeyoung&#39;s Blog" type="application/atom+xml">
    

    
        <link rel="icon" href="/favicon.ico">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">
    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
</head>
</html>
<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Jaeyoung&#39;s Blog</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">Main</a>
                
                    <a class="main-nav-link" href="/archives">TimeLine</a>
                
                    <a class="main-nav-link" href="/categories">Category</a>
                
                    <a class="main-nav-link" href="/tags">Tag</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="검색" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '포스트',
            PAGES: 'Pages',
            CATEGORIES: '카테고리',
            TAGS: '태그',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">Main</a></td>
                
                    <td><a class="main-nav-link" href="/archives">TimeLine</a></td>
                
                    <td><a class="main-nav-link" href="/categories">Category</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Tag</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="검색" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>카테고리</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Log
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/Blog-Init/">Init Blog</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Study Notes
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Bayesian Statistics
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/01_Probability/">01. Probability</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/02_Distribution/">02. Distribution</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/03_Frequentist_inference/">03. Frequentist Inference</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/04_Bayesian_inference/">04. Bayesian Inference</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/05_Credible_Intervals/">05. Credible Intervals</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/06_Prior_Posterior_predictive/">06. Prior Predictive Distribution</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/07_Priors/">07. Priors</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/08_Bayesian_Modeling/">08. Bayesian Modeling</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/09_Monte_Carlo_Estimation/">09. Monte Carlo Estimation</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/10_Markov_chain_Monte_Carlo/">10. Markov Chain Monte Carlo</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/11_Linear_Regression/">11. Linear Regression</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/12_Prior_Sensitivity_Analysis/">12. Prior Sensitivity Analysis</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/13_Hierarchical_models/">13. Hierarchical Models</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/14_Predictive_Simulation/">14. Predictive Simulations</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/APPENDIX-1-MAP/">Appendix 1. Maximize a Posterior</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/APPENDIX-2-Empirical-Bayes/">Appendix 2. Empirical Bayes</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Machine Learning
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/machine-learning/My-interpretation-of-Machine-Learning/">Machine Learning</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Principal-Component-Analysis/">Principal Component Analysis</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Lagrangian-Multiplication/">Lagrangian Multiplication</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Distillation-Methods/">Distillation Methods</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Restrict-Boltzmann-Machines-1st/">Restrict Boltzmann Machines 1</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Restrict-Boltzmann-Machines-2nd/">Restrict Boltzmann Machines 2</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-1/">Hidden Markov Models 1</a></li>  <li class="file active"><a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-2/">Hidden Markov Models 2</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/KL Divergence/">KL Divergence</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Reinforcement Learning
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/01_Introduction/">01. Introduction</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/02-K-arm-Bandits-Problems/">02. K-arm Bandits Problems</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/03-Markov-Decision-Process/">03. Markov Decision Process</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/04-Policies-and-Value-Functions/">04. Policies and Value Functions</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/05-Policy-Evaluation-vs-Control/">05. Policy Evaluation & Control</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/06-Sample-based-Reinforcement-Learning/">06. Sample-based Reinforcement Learning</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                     </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-studynotes/machine-learning/Hidden_Markov_Models-2" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/Study-Notes/">Study Notes</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Study-Notes/Machine-Learning/">Machine Learning</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/MachineLearning/">MachineLearning</a>, <a class="tag-link" href="/tags/StudyNotes/">StudyNotes</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-2/">
            <time datetime="2020-03-03T13:28:57.000Z" itemprop="datePublished">2020-03-03</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='https://github.com/taeuk-gang/taeuk-gang.github.io/raw/writing/source/_posts/studynotes/machine-learning/Hidden_Markov_Models-2.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='https://github.com/taeuk-gang/taeuk-gang.github.io/edit/writing/source/_posts/studynotes/machine-learning/Hidden_Markov_Models-2.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='https://github.com/taeuk-gang/taeuk-gang.github.io/commits/writing/source/_posts/studynotes/machine-learning/Hidden_Markov_Models-2.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            Hidden Markov Models 2
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">카탈로그</strong>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hidden-Markov-Models"><span class="toc-number">1.</span> <span class="toc-text">Hidden Markov Models</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Parameters-of-HMM"><span class="toc-number">1.0.1.</span> <span class="toc-text">Parameters of HMM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Algorithms-of-HMM"><span class="toc-number">1.1.</span> <span class="toc-text">Algorithms of HMM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Forward-Algorithms"><span class="toc-number">1.1.1.</span> <span class="toc-text">Forward Algorithms</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-1-Find-Likelihood-Distribution"><span class="toc-number">1.1.2.</span> <span class="toc-text">Problem 1: Find Likelihood Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Answer-to-Problem-1-Forward-Backward-Algorithm"><span class="toc-number">1.1.3.</span> <span class="toc-text">Answer to Problem 1: Forward/Backward Algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-2-Find-the-Most-Likely-Sequence-of-Hidden-States"><span class="toc-number">1.1.4.</span> <span class="toc-text">Problem 2: Find the Most Likely Sequence of Hidden States</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Answer-to-Problem-2-Viterbi-Algorithm"><span class="toc-number">1.1.5.</span> <span class="toc-text">Answer to Problem 2: Viterbi Algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-3-Training-HMM"><span class="toc-number">1.1.6.</span> <span class="toc-text">Problem 3: Training HMM</span></a></li></ol></li></ol></li></ol>
                </div>
            
        
        
            <h1 id="Hidden-Markov-Models"><a href="#Hidden-Markov-Models" class="headerlink" title="Hidden Markov Models"></a>Hidden Markov Models</h1><p>Udemy 강좌: <a href="https://www.udemy.com/course/unsupervised-machine-learning-hidden-markov-models-in-python" target="_blank" rel="noopener">https://www.udemy.com/course/unsupervised-machine-learning-hidden-markov-models-in-python</a></p>
<p>Hidden Markov model(HMM)은 다음과 같이 maximum likelihood estimation을 이용해서 파라미터를 추정하게 된다.<br>$$<br>\theta^* = \underset{\theta}{\text{argmax}} ~ p(x|\theta)<br>$$<br>다음으로, HMM의 파라미터가 무엇인지 적어본다. $\theta = ?$</p>
<h3 id="Parameters-of-HMM"><a href="#Parameters-of-HMM" class="headerlink" title="Parameters of HMM"></a>Parameters of HMM</h3><p>Markov model에서의 parameter는 initial distribution vector $\pi$와 state transition matrix $A$였다. HMM에서는 state-to-observation matrix $B$가 추가된다. 즉, $\pi, A, B$가 학습 parameter가 된다.</p>
<ul>
<li><p>$\pi$</p>
<p>Initial distribution. row vector이며, hidden state 개수가 $M$개일때, $\pi$는 $(1, M)$ 모양이다. $\pi(i)$하면, $i$번재 state의 initial 확률이다.</p>
</li>
<li><p>$A$</p>
<p>Hidden state transition matrix. 간단하게 state transition matrix이라고도 하며, $t$에서의 hidden state가 주어졌을 때, $t+1$에서의 hidden state의 확률분포이다. 즉, $p(s_{t+1}|s_t)$을 표현한다. 따라서, observation의 종류가 $D$개일때, $M \rightarrow D$이므로, $(M, D)$ 모양이다. $A(i, j)$의 원소는 $p(s_{t+1} = j | s_t = i)$를 의미한다.</p>
</li>
<li><p>$B$</p>
<p>Observation transition matrix이며, $t$에서의 hidden state가 주어졌을 때, $t$에서의 observation의 확률분포이다. $p(x_t|s_t)$를 표현한다. $B(j, k)$의 원소는 $p(x_t = k|s_t = j)$를 의미한다.</p>
</li>
</ul>
<p>이들을 이용한 연산의 예를 잠깐 몇개 들어보면, (Sequence의 시작 index는 1이다.)</p>
<ul>
<li>$\pi B = \sum_i \pi(i) B(i,:) = \sum_{z_1} p(z_1)p(x_1|z_1) =  p(x_1)$이다.</li>
<li>$\pi A B = \sum_{i,j} \pi(i) B(i,j) A(j,:) = \sum_{z_1, z_2} p(z_1)p(z_2|z_1)p(x_2|z_2) = p(x_2)$이다.</li>
</ul>
<h2 id="Algorithms-of-HMM"><a href="#Algorithms-of-HMM" class="headerlink" title="Algorithms of HMM"></a>Algorithms of HMM</h2><p>HMM에서도 다른 확률 모델과 마찬가지로 forward propagation, backward propagation과정이 존재한다.</p>
<h3 id="Forward-Algorithms"><a href="#Forward-Algorithms" class="headerlink" title="Forward Algorithms"></a>Forward Algorithms</h3><p>HMM의 forward 알고리즘은 데이터셋의 확률, 즉, likelihood를 계산하는 알고리즘으로 대표된다. Markov model과는 달리, HMM의 likelihood는 곧바로 파라미터로 나타낼 수가 없어서 likelihood를 적절히 변형해야 한다. 그리고 단순히 변형해도, 그 계산의 time complexity가 매우 커서 계산 최적화를 위한 작업을 해 줘야 한다.</p>
<h3 id="Problem-1-Find-Likelihood-Distribution"><a href="#Problem-1-Find-Likelihood-Distribution" class="headerlink" title="Problem 1: Find Likelihood Distribution"></a>Problem 1: Find Likelihood Distribution</h3><p>파라미터 $\pi, A, B$를 바탕으로 likelihood를 계산할 수 있어야 한다. Likelihood가 있어야 ML 추정법을 적용할 수 있기 때문. Likelihood는 $p(x|\pi, A,B)$와 같으며, observation $x$의 joint distribution에 해당한다.</p>
<p>파라미터는 수식의 모든 term에 존재하므로, 생략한다. 먼저, likelihood는 다음과 같다. $T$는 전체 sequence 길이이다. 이 likelihood를 파라미터에 대한 식으로 바꿔주어야 한다.<br>$$<br>p(x) = p(x_1, x_2, …, x_T)<br>$$<br>이것을 hidden Markov model 구조(확률 그래프 모델이니까)에 따라 factorize하기 위해, hidden variable $z$를 삽입한다 (Marginalize).<br>$$<br>p(x) = \sum_{z_1} \sum_{z_2} \cdots \sum_{z_T}p(x_1, x_2, …, x_T, z_1, z_2, …, z_T)<br>$$<br>이제 factorize한다.<br>$$<br>p(x) = \sum_{z_1} \sum_{z_2} \cdots \sum_{z_T} p(z_1) p(x_1|z_1) \prod_{t=2}^{T} p(z_{t}|z_{t-1})p(x_t|z_t)<br>$$<br>이제 parameter에 대한 식으로 바꿀 수 있다.<br>$$<br>p(x) = \sum_{z_1} \sum_{z_2} \cdots \sum_{z_T} \pi(z_1) B(z_1, x_1) \prod_{t=2}^T A(z_{t-1}, z_t) B(z_t, x_t)<br>$$<br>그런데, 이 식의 time complexity를 봐야 한다. 위 식은 결국, 모든 hidden state 조합을 더하는 것이다. Hidden state의 개수는 $M$개이고, 이게 $T$-time 만큼 있으므로, $M^T$개의 hidden state조합이 존재한다. 또한, 하나의 hidden state 조합을 구하기 위해서는 $O(T)$시간이 걸리며, 총 $O(TM^T)$ 시간이 걸리게 된다. 이것은 exponential한 time으로, 매우 비효율적이다.</p>
<h3 id="Answer-to-Problem-1-Forward-Backward-Algorithm"><a href="#Answer-to-Problem-1-Forward-Backward-Algorithm" class="headerlink" title="Answer to Problem 1: Forward/Backward Algorithm"></a>Answer to Problem 1: Forward/Backward Algorithm</h3><p>그런데, 위 $p(x)$에는 겹치는 연산이 상당히 많다. 이것을 factorize해서(인수분해) 좀 더 효율적으로 $p(x)$를 계산할 수 있을 것 같다.</p>
<p>우선, $T=2, M=2$인 경우를 생각해본다.<br>$$<br>p(x) = \sum_{z_1} \sum_{z_2} \pi(z_1)B(z_1, x_1)\prod_{t=2}^T A(z_{t-1}, z_t)B(z_t, x_t)<br>$$</p>
<p>$$<br>= \pi(1)B(1, x_1)A(1, 1)B(1, x_2) +<br>$$</p>
<p>$$<br>\pi(1)B(1, x_1)A(1, 2)B(2, x_2) +<br>$$</p>
<p>$$<br>\pi(2)B(2, x_1)A(2, 1)B(1, x_2) +<br>$$</p>
<p>$$<br>\pi(2)B(2, x_1)A(2, 2)B(2, x_2) +<br>$$</p>
<p>그런데, 중복된 연산이 너무 많다. 따라서, factorize를 해 주자.<br>$$<br>p(x) =<br>$$<br>$$<br>\pi(1)B(1, x_1)[A(1, 1)B(1, x_2) + A(1, 2)B(2, x_2)] +<br>$$</p>
<p>$$<br>\pi(2)B(2, x_1)[A(2, 1)B(1, x_2) + A(2, 2)B(2, x_2)]<br>$$</p>
<p>$T=3, M=2$인 경우도 마찬가지로 할 수 있다. 수식으로 보면 다음처럼 표현할 수 있다.<br>$$<br>p(x) = \sum_{z_1} \sum_{z_2} \sum_{z_3} p(z_1) p(x_1|z_1) \prod_{t=2}^3 p(z_t|z_{t-1})p(x_t|z_t)<br>$$<br>$$<br>= \sum_{z_1} \sum_{z_2} \sum_{z_3} p(z_1)p(x_1|z_1)p(z_2|z_1)p(x_2|z_2)p(z_3|z_2)p(x_3|z_3)<br>$$</p>
<p>$$<br>= \sum_{z_3} p(x_3|z_3) \sum_{z_2} p(x_2|z_2)p(z_3|z_2) \sum_{z_1} p(z_1)p(x_1|z_1)p(z_2|z_1)<br>$$</p>
<p>위 식을 다음처럼 변형해본다.<br>$$<br>\sum_{z_3} p(x_3|z_3) \sum_{z_2} p(z_3|z_2) [p(x_2|z_2) \sum_{z_1} p(z_2|z_1)[p(x_1|z_1) p(z_1)]]<br>$$<br>여기서, $\alpha$라고 하는 놈을 정의한다.<br>$$<br>\alpha(3, z_3) = p(x_3|z_3) \sum_{z_2} p(z_3|z_2) \alpha(2, z_2)<br>$$<br>$$<br>\alpha(2, z_2) = p(x_2|z_2) \sum_{z_1} p(z_2|z_1) \alpha(1, z_1)<br>$$</p>
<p>$$<br>\alpha(1, z_1) = p(x_1|z_1)p(z_1)<br>$$</p>
<p>이때, $p(x)$는 다음처럼 된다.<br>$$<br>p(x) = \sum_{z_3}\alpha(3, z_3)<br>$$<br>즉, 다음처럼 일반화가 가능하다.<br>$$<br>p(x) = \sum_{z_T} \alpha(T, z_T)<br>$$<br>$$<br>\alpha(t, z_t) = p(x_t|z_t) \sum_{z_{t-1}} p(z_t|z_{t-1}) \alpha(t-1, z_{t-1})<br>$$</p>
<p>$$<br>\alpha(1, z_1) = p(x_1|z_1)p(z_1)<br>$$</p>
<p>이렇게 되면, likelihood $p(x)$를 계산하는데, $O(MT)$면 끝이 난다.</p>
<h3 id="Problem-2-Find-the-Most-Likely-Sequence-of-Hidden-States"><a href="#Problem-2-Find-the-Most-Likely-Sequence-of-Hidden-States" class="headerlink" title="Problem 2: Find the Most Likely Sequence of Hidden States"></a>Problem 2: Find the Most Likely Sequence of Hidden States</h3><p>Likelihood를 구했다면, 이번엔 가장 probable한 hidden states의 sequence를 찾을 수 있어야 한다. 즉,<br>$$<br>z^* = \underset{z}{ \text{argmax} } ~ p(z|x)<br>$$</p>
<p>를 만족하는 hidden states $z$의 joint distribution을 계산할 수 있어야 한다.</p>
<p>그런데, 이때, 위 식은 다음처럼 정리가 가능하다.<br>$$<br>z^* = \underset{z}{ \text{argmax} } ~ p(z|x) = \underset{z}{ \text{argmax} } ~ \frac{p(x,z)}{p(x)} = \underset{z}{ \text{argmax} } ~ p(x, z)<br>$$<br>그런데, 여기서, $p(x, z)$는 $p(x)$를 구하는 식에서 marginalization만 빼면 된다. 즉,<br>$$<br>p(x, z) = p(z_1)p(x_1|z_1) \prod_{i=2}^T p(z_{t}|z_{t-1})p(x_t|z_t)<br>$$<br>이다. 하나의 joint probability를 계산하려면 $O(T)$시간이 걸리는 셈. 그러면, observations들에 맞게 가장 그럴듯한 hidden state들을 찾으려면, hidden state의 모든 조합을 저 식에 넣어보고 가장 큰 확률값을 주는 조합을 고르면 될 것이다. 그러나, 이 방법은 $O(TM^T)$가 걸린다.</p>
<h3 id="Answer-to-Problem-2-Viterbi-Algorithm"><a href="#Answer-to-Problem-2-Viterbi-Algorithm" class="headerlink" title="Answer to Problem 2: Viterbi Algorithm"></a>Answer to Problem 2: Viterbi Algorithm</h3><p>지금, $p(x, z)$가 가장 큰 $z$조합을 구해야 한다. HMM은 Markov model이기 때문에 $t-1$까지 최적의 $z$ sequence를 구해놨다면, $t$에서의 $z_t$는 greedy하게 선택하면 $t$까지의 $z$ sequence는 optimal이다. 즉, $t=1$에서, $p(z_1)p(x_1|z_1)$이 최대가 되는 $z_1$를 구하고, $t=2$에서, $p(z_2|z_1)p(x_2|z_2)$이 최대가 되는 $z_2$를 구하고 이런식으로 앞에서부터 greedy하게 선택해도 된다는 것이다.</p>
<h3 id="Problem-3-Training-HMM"><a href="#Problem-3-Training-HMM" class="headerlink" title="Problem 3: Training HMM"></a>Problem 3: Training HMM</h3><p>다음을 만족하는 parameter $\pi, A, B$를 계산한다.<br>$$<br>A^* , B^* , \pi^* = \underset{A,B,\pi}{ \text{argmax} } ~ p(x|A,B,\pi)<br>$$</p>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/studynotes/machine-learning/KL Divergence/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">다음 글</strong>
            <div class="article-nav-title">
                
                    KL Divergence
                
            </div>
        </a>
    
    
        <a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-1/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">이전 글</strong>
            <div class="article-nav-title">Hidden Markov Models 1</div>
        </a>
    
</nav>





    
    

    <script src="https://utteranc.es/client.js"
        repo="taeuk-gang/taeuk-gang.github.io"
        issue-term="title"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>



<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            Lee Jaeyoung &copy; 2020 
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <!-- <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a> -->
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>