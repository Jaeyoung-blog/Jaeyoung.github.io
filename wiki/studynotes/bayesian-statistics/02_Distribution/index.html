<!DOCTYPE html>
<html lang="ko">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    
    <title>02. Distribution | Jaeyoung&#39;s Blog</title>
    
    
        <meta name="keywords" content="StudyNotes,BayesianStatistics">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="DistributionBackgroundIndicator Function어떤 조건이 만족했을때, 1을 반환하고, 만족하지 못하면 0을 반환하는 함수이다.$$\mathbb{I}{\text{cond}(x)}(x) = \begin{cases} 1 &amp;amp; \text{if cond(x) is True} \ 0 &amp;amp; \text{if cond(x) is Fal">
<meta name="keywords" content="StudyNotes,BayesianStatistics">
<meta property="og:type" content="article">
<meta property="og:title" content="02. Distribution">
<meta property="og:url" content="https://wayexists02.github.io/wiki/studynotes/bayesian-statistics/02_Distribution/index.html">
<meta property="og:site_name" content="Jaeyoung&#39;s Blog">
<meta property="og:description" content="DistributionBackgroundIndicator Function어떤 조건이 만족했을때, 1을 반환하고, 만족하지 못하면 0을 반환하는 함수이다.$$\mathbb{I}{\text{cond}(x)}(x) = \begin{cases} 1 &amp;amp; \text{if cond(x) is True} \ 0 &amp;amp; \text{if cond(x) is Fal">
<meta property="og:locale" content="ko">
<meta property="og:updated_time" content="2020-03-03T01:55:09.437Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="02. Distribution">
<meta name="twitter:description" content="DistributionBackgroundIndicator Function어떤 조건이 만족했을때, 1을 반환하고, 만족하지 못하면 0을 반환하는 함수이다.$$\mathbb{I}{\text{cond}(x)}(x) = \begin{cases} 1 &amp;amp; \text{if cond(x) is True} \ 0 &amp;amp; \text{if cond(x) is Fal">
    

    
        <link rel="alternate" href="/atom.xml" title="Jaeyoung&#39;s Blog" type="application/atom+xml">
    

    
        <link rel="icon" href="/favicon.ico">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">
    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
</head>
</html>
<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Jaeyoung&#39;s Blog</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">Main</a>
                
                    <a class="main-nav-link" href="/archives">TimeLine</a>
                
                    <a class="main-nav-link" href="/categories">Category</a>
                
                    <a class="main-nav-link" href="/tags">Tag</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="검색" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '포스트',
            PAGES: 'Pages',
            CATEGORIES: '카테고리',
            TAGS: '태그',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">Main</a></td>
                
                    <td><a class="main-nav-link" href="/archives">TimeLine</a></td>
                
                    <td><a class="main-nav-link" href="/categories">Category</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Tag</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="검색" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>카테고리</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Log
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/Blog-Init/">Init Blog</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Study Notes
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Bayesian Statistics
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/01_Probability/">01. Probability</a></li>  <li class="file active"><a href="/wiki/studynotes/bayesian-statistics/02_Distribution/">02. Distribution</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/03_Frequentist_inference/">03. Frequentist Inference</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/04_Bayesian_inference/">04. Bayesian Inference</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/05_Credible_Intervals/">05. Credible Intervals</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/06_Prior_Posterior_predictive/">06. Prior Predictive Distribution</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/07_Priors/">07. Priors</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/08_Bayesian_Modeling/">08. Bayesian Modeling</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/09_Monte_Carlo_Estimation/">09. Monte Carlo Estimation</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/10_Markov_chain_Monte_Carlo/">10. Markov Chain Monte Carlo</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/11_Linear_Regression/">11. Linear Regression</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/12_Prior_Sensitivity_Analysis/">12. Prior Sensitivity Analysis</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/13_Hierarchical_models/">13. Hierarchical Models</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/14_Predictive_Simulation/">14. Predictive Simulations</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/APPENDIX-1-MAP/">Appendix 1. Maximize a Posterior</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/APPENDIX-2-Empirical-Bayes/">Appendix 2. Empirical Bayes</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Machine Learning
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/machine-learning/Distillation-Methods/">Distillation Methods</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-1/">Hidden Markov Models 1</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-2/">Hidden Markov Models 2</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/KL Divergence/">KL Divergence</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Lagrangian-Multiplication/">Lagrangian Multiplication</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/My-interpretation-of-Machine-Learning/">Machine Learning</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Principal-Component-Analysis/">Principal Component Analysis</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Restrict-Boltzmann-Machines-1st/">Restrict Boltzmann Machines 1</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Restrict-Boltzmann-Machines-2nd/">Restrict Boltzmann Machines 2</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Reinforcement Learning
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/01_Introduction/">01. Introduction</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/02-K-arm-Bandits-Problems/">02. K-arm Bandits Problems</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/03-Markov-Decision-Process/">03. Markov Decision Process</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/04-Policies-and-Value-Functions/">04. Policies and Value Functions</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/05-Policy-Evaluation-vs-Control/">05. Policy Evaluation & Control</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/06-Sample-based-Reinforcement-Learning/">06. Sample-based Reinforcement Learning</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/07-Off-Policy-Learning/">07. Off-policy Learning</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/08-Temporal-Difference-Learning/">08. Temporal Difference Learning</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/09-Models-and-Planning/">09. Models and Planning</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/10-Prediction-and-Control-with-Function-Approximation/">10. Prediction and Control with Function Approximation</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/11-Feature-Construction/">11. Feature Construction</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/12-Controls-with-Approximation/">12. Controls with Approximation</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/13-Policy-Gradient/">13. Policy Gradient</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/Appendix-1-RL-Cheatsheet/">Appendix 01. Which Algorithm Should be selected</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                     <li class="file"><a href="/wiki/index/">Home</a></li>  </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-studynotes/bayesian-statistics/02_Distribution" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/Study-Notes/">Study Notes</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Study-Notes/Bayesian-Statistics/">Bayesian Statistics</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/BayesianStatistics/">BayesianStatistics</a>, <a class="tag-link" href="/tags/StudyNotes/">StudyNotes</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/studynotes/bayesian-statistics/02_Distribution/">
            <time datetime="2020-03-01T12:08:01.000Z" itemprop="datePublished">2020-03-01</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='https://github.com/wayexists02/wayexists02.github.io/raw/writing/source/_posts/studynotes/bayesian-statistics/02_Distribution.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='https://github.com/wayexists02/wayexists02.github.io/edit/writing/source/_posts/studynotes/bayesian-statistics/02_Distribution.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='https://github.com/wayexists02/wayexists02.github.io/commits/writing/source/_posts/studynotes/bayesian-statistics/02_Distribution.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            02. Distribution
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">카탈로그</strong>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Distribution"><span class="toc-number">1.</span> <span class="toc-text">Distribution</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Background"><span class="toc-number">1.1.</span> <span class="toc-text">Background</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Indicator-Function"><span class="toc-number">1.1.1.</span> <span class="toc-text">Indicator Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Expected-Values"><span class="toc-number">1.1.2.</span> <span class="toc-text">Expected Values</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Variance"><span class="toc-number">1.1.3.</span> <span class="toc-text">Variance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scaling-Random-Variable-vs-Many-Random-Variables"><span class="toc-number">1.1.4.</span> <span class="toc-text">Scaling Random Variable vs Many Random Variables</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discrete-Distribution"><span class="toc-number">1.2.</span> <span class="toc-text">Discrete Distribution</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Bernoulli-Distribution"><span class="toc-number">1.2.1.</span> <span class="toc-text">Bernoulli Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Binomial-Distribution"><span class="toc-number">1.2.2.</span> <span class="toc-text">Binomial Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Geometric-Distribution"><span class="toc-number">1.2.3.</span> <span class="toc-text">Geometric Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multinomial-Distribution"><span class="toc-number">1.2.4.</span> <span class="toc-text">Multinomial Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Poisson-Distribution"><span class="toc-number">1.2.5.</span> <span class="toc-text">Poisson Distribution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Continuous-Distribution"><span class="toc-number">1.3.</span> <span class="toc-text">Continuous Distribution</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Exponential-Distribution"><span class="toc-number">1.3.1.</span> <span class="toc-text">Exponential Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gamma-Distribution"><span class="toc-number">1.3.2.</span> <span class="toc-text">Gamma Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Uniform-Distribution"><span class="toc-number">1.3.3.</span> <span class="toc-text">Uniform Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Beta-Distribution"><span class="toc-number">1.3.4.</span> <span class="toc-text">Beta Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Normal-Distribution"><span class="toc-number">1.3.5.</span> <span class="toc-text">Normal Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#t-Distribution"><span class="toc-number">1.3.6.</span> <span class="toc-text">t-Distribution</span></a></li></ol></li></ol></li></ol>
                </div>
            
        
        
            <h1 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h1><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Indicator-Function"><a href="#Indicator-Function" class="headerlink" title="Indicator Function"></a>Indicator Function</h3><p>어떤 조건이 만족했을때, 1을 반환하고, 만족하지 못하면 0을 반환하는 함수이다.<br>$$<br>\mathbb{I}<em>{\text{cond}(x)}(x) = \begin{cases} 1 &amp; \text{if cond(x) is True} \ 0 &amp; \text{if cond(x) is False} \end{cases}<br>$$<br>Indicator function은 다음과 같이 동전 던지기에 대한 확률같은 것을 표현할 때 용이하다.<br>$$<br>P(X|\theta) = \theta \cdot \mathbb{I}</em>{\text{head}} + (1 - \theta) \cdot \mathbb{I}_{\text{tail}}<br>$$</p>
<h3 id="Expected-Values"><a href="#Expected-Values" class="headerlink" title="Expected Values"></a>Expected Values</h3><p><strong>기댓값</strong>이라고도 불리며, 확률적인 관점에서 본 <strong>“평균”</strong>이다.<br>$$<br>E[X] = \sum\limits_{x} p_x x<br>$$<br>각 샘플들에 비중치를 곱해서 모두 더한 것이다.</p>
<p>일반적으로 생각할 수 있는 평균값은 모든 샘플들에 같은 비중치를 둔 기댓값과 같다.</p>
<h3 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h3><p><strong>분산</strong>이라고도 불리며, 샘플들이 평균 또는 기댓값으로부터 얼마나 떨어져서 분포하는가, 즉, <strong>샘플들이 얼마나 넓게 퍼져있는가</strong>를 나타낸다.<br>$$<br>\text{Var}[X] = E[(X-\mu)^2] = \sum\limits_{x} p_x(x - \mu)^2<br>$$<br>평균과의 거리의 제곱을 평균한 것인데, 단위가 제곱이 된다. 따라서 단위를 일치시키기 위해 제곱근을 씌우는데, 이를 <strong>standard deviation(표준편차)</strong>라고 부른다.<br>$$<br>\text{Std.}[X] = \sigma(X) = \sqrt{\text{Var}[X]}<br>$$</p>
<h3 id="Scaling-Random-Variable-vs-Many-Random-Variables"><a href="#Scaling-Random-Variable-vs-Many-Random-Variables" class="headerlink" title="Scaling Random Variable vs Many Random Variables"></a>Scaling Random Variable vs Many Random Variables</h3><p>Random variable을 scaling 한다는 것은, 분포를 넓게 피는것을 의미한다. random variable $$X$$를 $$c$$배 scaling하는 것은 $$cX$$로 표기한다.</p>
<p>반면, random variable $$X$$를 여러번 시행하는 것은 $$\sum_i^n X_i$$로 표기한다. 둘이 분명히 다른데, $$cX$$의 경우, 1번 샘플링하는 것이고, $$\sum X$$는 여러번 샘플링 하는 것이다.</p>
<p>예를들어, $$X$$가 베르누이 분포를 따르고, 1일 확률이 0.7 이라면, $$10X$$는 0일 확률이 0.3, <strong>10일 확률</strong>이 0.7인 것이다.</p>
<p>반면, $$\sum_i^{10} X_i$$는 1이 나올 확률이 0.7인 분포에서 10번 샘플링하는 것이다.</p>
<h2 id="Discrete-Distribution"><a href="#Discrete-Distribution" class="headerlink" title="Discrete Distribution"></a>Discrete Distribution</h2><h3 id="Bernoulli-Distribution"><a href="#Bernoulli-Distribution" class="headerlink" title="Bernoulli Distribution"></a>Bernoulli Distribution</h3><p>Sample space의 크기가 2(event 개수가 2개)라고 추정되는 random variable $X$가 있을때, 이 $X$는 Bernoulli distribution(베르누이 분포)을 따른다. 베르누이 분포를 따르는 random variable의 1회 experiment을 베르누이 시행이라고 한다.<br>$$<br>\text{Bern}(X|\theta) = \theta<em>\mathbb{I}<em>{X=1} + (1 - \theta) * \mathbb{I}</em>{X=0}<br>$$<br><strong>Expected value:</strong><br>$$<br>E[X] = \theta<br>$$<br><strong>Variance:</strong><br>$$<br>\sigma^2(X) = \theta * (1 - \theta)^2 + (1-\theta)</em>(0 - \theta)^2 = \theta(1-\theta)<br>$$</p>
<h3 id="Binomial-Distribution"><a href="#Binomial-Distribution" class="headerlink" title="Binomial Distribution"></a>Binomial Distribution</h3><p>베르누이 분포를 따르는 experiment를 여러번 시행했을 때, 한 결과가 몇 번이 나왔는가에 대한 분포이다. 흔히, 동전을 10번 던졌을때, 앞면이 몇 번 나오는지에 대한 분포라고 이해하면 편하다. 동전 던지기 1회는 베르누이 시행이다.<br>$$<br>\text{Binom}(n, x|\theta) = \begin{pmatrix} n \ x \end{pmatrix} \theta^x(1-\theta)^{n-x}<br>$$<br><strong>Expected value:</strong><br>$$<br>E[X] = n\theta<br>$$<br><strong>Variance:</strong><br>$$<br>\sigma^2(X) = n\theta(1-\theta)<br>$$</p>
<h3 id="Geometric-Distribution"><a href="#Geometric-Distribution" class="headerlink" title="Geometric Distribution"></a>Geometric Distribution</h3><p>베르누이 시행을 여러번 반복하는데, 어떤 event가 최초로 일어날때 까지의 시행한 횟수는 geometric distribution을 따른다. (기하분포). $\theta$는 베르누이 시행 1회에서 그 event가 성공할 확률이다.<br>$$<br>\text{Geom}(x|\theta) = \theta * (1-\theta)^{x-1}<br>$$<br><strong>Expected value:</strong><br>$$<br>E[X] = \frac{1}{\theta}<br>$$</p>
<h3 id="Multinomial-Distribution"><a href="#Multinomial-Distribution" class="headerlink" title="Multinomial Distribution"></a>Multinomial Distribution</h3><p>시행이 베르누이 시행이 아니라, 여러 개의 event가 나올 수 있는 시행일 때의 binomial distribution을 의미한다.<br>$$<br>\text{Multinom}(n, x_1,…,x_{n}|\theta_1, \theta_2, …, \theta_{n}) = \begin{pmatrix} n \ x_1, x_2, …, x_n \end{pmatrix}\theta_1^{x_1}<em>\theta^{x_2}</em> \cdots*\theta^{x_n}<br>$$</p>
<h3 id="Poisson-Distribution"><a href="#Poisson-Distribution" class="headerlink" title="Poisson Distribution"></a>Poisson Distribution</h3><p>포아송 분포는, 어느 시간 간격 내에 그 event가 몇 번 일어날지에 대한 분포이다. 해당 시간 간격동안에 event가 발생하는 횟수를 $\lambda$라고 하면, 다음과 같다.<br>$$<br>\text{Poisson}(x|\lambda) = \frac{\lambda^xe^{-\lambda}}{x!}<br>$$<br>Expected value:<br>$$<br>E[X] = \lambda<br>$$<br>(애초에 $\lambda$ 정의가 그냥 기댓값이다.)</p>
<p>여기서, 만약에 binomial distribution을 따르는데, 동전이 앞면이 나올 확률이 너무나도 희박하고, 동전 던지기 experiment를 무한번 한 경우, 그 무한번의 experiment를 일정 기간의 시간이라고 간주하게 되면 poisson distribution와 같다.</p>
<h2 id="Continuous-Distribution"><a href="#Continuous-Distribution" class="headerlink" title="Continuous Distribution"></a>Continuous Distribution</h2><p>Sample space가 continuous한 경우의 distribution을 말함.</p>
<h3 id="Exponential-Distribution"><a href="#Exponential-Distribution" class="headerlink" title="Exponential Distribution"></a>Exponential Distribution</h3><p>특정 일이 일어날 때 까지 걸린 시간 또는 기다린 시간의 분포는 exponential distribution을 따른다.<br>$$<br>\text{Exp}(\lambda) = \lambda e^{-\lambda x} \mathbb{I}_{ x \geq 0 }<br>$$<br>여기서 $\lambda$는 어떤 시간 동안에 사건이 발생하는 횟수의 비율을 말한다. 예를 들어, 10분 동안 버스가 3대 오면 $\lambda = 0.3$이다(시간을 10분 단위로 했을 때).</p>
<h3 id="Gamma-Distribution"><a href="#Gamma-Distribution" class="headerlink" title="Gamma Distribution"></a>Gamma Distribution</h3><p>버스가 올때까지 걸리는 시간을 측정하는 시행이 여러 번 있고, 그들의 총합 시간은 gamma distribution을 따른다. 쉽게 말해서, Gamma distribution을 따르는 $Y$는 exponential distribution을 따르는 $X_i$의 합과 같다.<br>$$<br>Y = \sum_i X_i \<br>p(y|\alpha,\beta) = \frac{\beta^{\alpha}}{\Gamma(\alpha)}y^{\alpha-1}e^{-\beta y} \mathbb{I}_{y \geq 0}(y)<br>$$<br>감마분포는 $\alpha$와 $\beta$를 파라미터로 삼으며, $\alpha = n$, $\beta = \lambda$가 된다.</p>
<p>$$\alpha$$는 shape parameter로, $$\alpha=1$$이면, exponential distribution이 된다. 또한, $$\alpha$$가 0에 가까워질수록 right-skewed가 된다. $$\alpha$$가 커질수록 normal distribution에 가까워지면서 skewness가 줄어든다(한쪽으로 치우치지 않는다).</p>
<p>$$\beta = \lambda$$는 rate parameter로, $$\theta = \frac{1}{\beta}$$는 scale parameter이다. 서로 역수 관계이며, 감마 분포를 표기할때, $$(\alpha, \beta)$$로 parameterize하기도 하고 $$(k, \theta)$$로 parameterize하기도 한다. $$\alpha=k$$이지만, $$\beta = \frac{1}{\theta}$$이다. $$\theta$$는 scale parameter로, rate의 역수이다. Scale parameter는 분산의 scaling 정도이며, 클수록 넓게 퍼진다. 즉, rate가 작을수록 넓게 퍼지며, random variable $$X$$의 $$c$$배 scale인 $$cX$$는 $$(k, c\theta)$$가 되는 셈.</p>
<p>$$\sum_i^{n} X_i$$는 $$(nk, \theta)$$ 효과를 얻는다! 이걸 보면 $$\alpha$$가 exponential의 횟수와 관련이 있을지도 모른다.</p>
<p><strong>Expected Value:</strong><br>$$<br>E[X] = \frac{\alpha}{\beta}<br>$$<br><strong>Variance:</strong><br>$$<br>\sigma^2(X) = \frac{\alpha}{\beta^2}<br>$$</p>
<h3 id="Uniform-Distribution"><a href="#Uniform-Distribution" class="headerlink" title="Uniform Distribution"></a>Uniform Distribution</h3><p>모든 sample space범위의 단위 interval에서 확률이 같다.<br>$$<br>\text{Uni}(X) = \frac{1}{b-a}\mathbb{I}_{ a \leq x \leq b }<br>$$<br><strong>Expected Value:</strong><br>$$<br>E[X] = \frac{a+b}{2}<br>$$<br>(a~b까지 나올 확률이 같으므로 샘플링 여러번 하다 보면 평균값은 중앙값인 $\frac{a+b}{2}$이 된다.)</p>
<p><strong>Variance:</strong><br>$$<br>\sigma^2(X) = \frac{(b-a)^2}{12}<br>$$</p>
<h3 id="Beta-Distribution"><a href="#Beta-Distribution" class="headerlink" title="Beta Distribution"></a>Beta Distribution</h3><p>Sample space가 0과 1 사이인 분포. 따라서 확률을 모델링할때 이용하기도 한다.<br>$$<br>\text{Beta}(\alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}<br>$$<br>여기서, $\Gamma(x) = (x-1)!$이다. 앞의 $\Gamma$ term들을 풀어보면 binomial coefficient와 비슷하게 생겨서 나중에 binomial distribution을 적분할때, gamma distribution을 이용하면 매우 유용하다.</p>
<p><strong>Expected Value:</strong><br>$$<br>E[X] = \frac{\alpha}{\alpha + \beta}<br>$$<br><strong>Variance:</strong><br>$$<br>\sigma^2(X) = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}<br>$$</p>
<h3 id="Normal-Distribution"><a href="#Normal-Distribution" class="headerlink" title="Normal Distribution"></a>Normal Distribution</h3><p>정규 분포.<br>$$<br>p(x|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})<br>$$<br><strong>Expected Value:</strong><br>$$<br>E[X] = \mu<br>$$<br><strong>Variance:</strong><br>$$<br>\text{Var}(X) = \sigma^2<br>$$<br>만약, iid(independent identical distribution)에서 샘플링된 여러 샘플들, 즉, 똑같은 분포로부터 독립적인 시행으로 샘플링한 여러 샘플들의 평균 $\bar{X}$은 정규 분포를 따른다. 샘플의 개수를 $n$, 그 샘플들을 샘플링한, 즉, 하나의 샘플을 샘플링한 분포의 실제 평균을 $\mu$, 분산을 $\sigma^2$이라고 했을 때, 다음을 만족한다.<br>$$<br>\bar{X} \sim \mathbb{N}(\mu, \frac{\sigma^2}{n})<br>$$<br>이를 central limit theorem(CLT) 이라고 부른다. 평균 $\mu$는 추정 대상이라서 모르지만, $\sigma^2$는 샘플들의 분산으로 대체한다. 즉, 우리가 샘플링한샘플들의 평균은 실제 샘플 평균으로부터 어느정도 가깝다는 것이다. 또한, 분산은 샘플수에 반비레하는데, 이는 샘플이 많을수록, 진짜 샘플 평균에 가까워진다는 것을 알 수 있다.</p>
<h3 id="t-Distribution"><a href="#t-Distribution" class="headerlink" title="t-Distribution"></a>t-Distribution</h3><p>Student-t 분포, test용 분포라고도 한다. </p>
<p>CLT에서, 샘플 평균의 분포를 standarize시키면 standard normal distribution이 아니라, t-distribution이 나온다. 분산값인 $\sigma^2$가 샘플 분산인 $S^2$으로 대체되기 때문이다.<br>$$<br>S^2 = \frac{\sum_i (\bar{X}-X_i)^2}{n-1}<br>$$<br>이러면, $\bar{X}$의 분포는 더 이상 normal distribution이 아닌, t-distribution을 따른다. $\nu = n-1$이라고 했을 때,<br>$$<br>\text{t}(x) = \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\sqrt{\nu\pi}}(1+\frac{x^2}{\nu})^{-(\frac{\nu+1}{2})}<br>$$<br>이때, $\nu$는 자유도, degree of freedom이라고 부른다.</p>
<p><strong>Expected Value: **<br>$$<br>E[X] = 0 <del>~</del>\text{if } \nu \geq 1<br>$$<br>**Variance:</strong><br>$$<br>\text{Var}(X) = \frac{\nu}{\nu-2} <del>~</del>\text{if } \nu \geq 2<br>$$</p>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/studynotes/bayesian-statistics/03_Frequentist_inference/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">다음 글</strong>
            <div class="article-nav-title">
                
                    03. Frequentist Inference
                
            </div>
        </a>
    
    
        <a href="/wiki/studynotes/bayesian-statistics/01_Probability/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">이전 글</strong>
            <div class="article-nav-title">01. Probability</div>
        </a>
    
</nav>





    
    

    <script src="https://utteranc.es/client.js"
        repo="taeuk-gang/taeuk-gang.github.io"
        issue-term="title"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>



<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            Lee Jaeyoung &copy; 2020 
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <!-- <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a> -->
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>