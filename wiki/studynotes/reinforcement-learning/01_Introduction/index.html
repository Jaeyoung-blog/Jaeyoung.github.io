<!DOCTYPE html>
<html lang="ko">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    
    <title>01. Introduction | Jaeyoung&#39;s Blog</title>
    
    
        <meta name="keywords" content="StudyNotes,ReinforcementLearning">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="IntroductionReinforcement Learning이란, 무엇을 할지에 대해 학습하는 것이다. 다르게 말하면, 어떤 상황이 입력으로 들어가서 어떤 액션이 출력되는 함수를 학습하는 것이다. Reinforcement learning에선, 두 가지 중요한 특징이 있는데, 다음과 같다.  Trails &amp;amp; erros search Delayed re">
<meta name="keywords" content="StudyNotes,ReinforcementLearning">
<meta property="og:type" content="article">
<meta property="og:title" content="01. Introduction">
<meta property="og:url" content="https://jaeyoung-blog.github.io/wiki/studynotes/reinforcement-learning/01_Introduction/index.html">
<meta property="og:site_name" content="Jaeyoung&#39;s Blog">
<meta property="og:description" content="IntroductionReinforcement Learning이란, 무엇을 할지에 대해 학습하는 것이다. 다르게 말하면, 어떤 상황이 입력으로 들어가서 어떤 액션이 출력되는 함수를 학습하는 것이다. Reinforcement learning에선, 두 가지 중요한 특징이 있는데, 다음과 같다.  Trails &amp;amp; erros search Delayed re">
<meta property="og:locale" content="ko">
<meta property="og:updated_time" content="2020-03-03T04:27:46.414Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="01. Introduction">
<meta name="twitter:description" content="IntroductionReinforcement Learning이란, 무엇을 할지에 대해 학습하는 것이다. 다르게 말하면, 어떤 상황이 입력으로 들어가서 어떤 액션이 출력되는 함수를 학습하는 것이다. Reinforcement learning에선, 두 가지 중요한 특징이 있는데, 다음과 같다.  Trails &amp;amp; erros search Delayed re">
    

    
        <link rel="alternate" href="/atom.xml" title="Jaeyoung&#39;s Blog" type="application/atom+xml">
    

    
        <link rel="icon" href="/favicon.ico">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">
    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
</head>
</html>
<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Jaeyoung&#39;s Blog</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">Main</a>
                
                    <a class="main-nav-link" href="/archives">TimeLine</a>
                
                    <a class="main-nav-link" href="/categories">Category</a>
                
                    <a class="main-nav-link" href="/tags">Tag</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="검색" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '포스트',
            PAGES: 'Pages',
            CATEGORIES: '카테고리',
            TAGS: '태그',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">Main</a></td>
                
                    <td><a class="main-nav-link" href="/archives">TimeLine</a></td>
                
                    <td><a class="main-nav-link" href="/categories">Category</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Tag</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="검색" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>카테고리</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Log
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/Blog-Init/">Init Blog</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Study Notes
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Bayesian Statistics
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/01_Probability/">01. Probability</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/02_Distribution/">02. Distribution</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/03_Frequentist_inference/">03. Frequentist Inference</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/04_Bayesian_inference/">04. Bayesian Inference</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/05_Credible_Intervals/">05. Credible Intervals</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/06_Prior_Posterior_predictive/">06. Prior Predictive Distribution</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/07_Priors/">07. Priors</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/08_Bayesian_Modeling/">08. Bayesian Modeling</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/09_Monte_Carlo_Estimation/">09. Monte Carlo Estimation</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/10_Markov_chain_Monte_Carlo/">10. Markov Chain Monte Carlo</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/11_Linear_Regression/">11. Linear Regression</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/12_Prior_Sensitivity_Analysis/">12. Prior Sensitivity Analysis</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/13_Hierarchical_models/">13. Hierarchical Models</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/14_Predictive_Simulation/">14. Predictive Simulations</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/APPENDIX-1-MAP/">Appendix 1. Maximize a Posterior</a></li>  <li class="file"><a href="/wiki/studynotes/bayesian-statistics/APPENDIX-2-Empirical-Bayes/">Appendix 2. Empirical Bayes</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Machine Learning
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/studynotes/machine-learning/My-interpretation-of-Machine-Learning/">Machine Learning</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Principal-Component-Analysis/">Principal Component Analysis</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Lagrangian-Multiplication/">Lagrangian Multiplication</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Distillation-Methods/">Distillation Methods</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Restrict-Boltzmann-Machines-1st/">Restrict Boltzmann Machines 1</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Restrict-Boltzmann-Machines-2nd/">Restrict Boltzmann Machines 2</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-1/">Hidden Markov Models 1</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/Hidden_Markov_Models-2/">Hidden Markov Models 2</a></li>  <li class="file"><a href="/wiki/studynotes/machine-learning/KL Divergence/">KL Divergence</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Reinforcement Learning
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file active"><a href="/wiki/studynotes/reinforcement-learning/01_Introduction/">01. Introduction</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/02-K-arm-Bandits-Problems/">02. K-arm Bandits Problems</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/03-Markov-Decision-Process/">03. Markov Decision Process</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/04-Policies-and-Value-Functions/">04. Policies and Value Functions</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/05-Policy-Evaluation-vs-Control/">05. Policy Evaluation & Control</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/06-Sample-based-Reinforcement-Learning/">06. Sample-based Reinforcement Learning</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/07-Off-Policy-Learning/">07. Off-policy Learning</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/08-Temporal-Difference-Learning/">08. Temporal Difference Learning</a></li>  <li class="file"><a href="/wiki/studynotes/reinforcement-learning/09-Models-and-Planning/">09. Models and Planning</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                     </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-studynotes/reinforcement-learning/01_Introduction" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/Study-Notes/">Study Notes</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Study-Notes/Reinforcement-Learning/">Reinforcement Learning</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/ReinforcementLearning/">ReinforcementLearning</a>, <a class="tag-link" href="/tags/StudyNotes/">StudyNotes</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/studynotes/reinforcement-learning/01_Introduction/">
            <time datetime="2020-03-03T01:00:00.000Z" itemprop="datePublished">2020-03-03</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href='https://github.com/taeuk-gang/taeuk-gang.github.io/raw/writing/source/_posts/studynotes/reinforcement-learning/01_Introduction.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='https://github.com/taeuk-gang/taeuk-gang.github.io/edit/writing/source/_posts/studynotes/reinforcement-learning/01_Introduction.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href='https://github.com/taeuk-gang/taeuk-gang.github.io/commits/writing/source/_posts/studynotes/reinforcement-learning/01_Introduction.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            01. Introduction
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">카탈로그</strong>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Overview-of-Reinforcement-Learning"><span class="toc-number">1.1.</span> <span class="toc-text">Overview of Reinforcement Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Unusual-amp-Unexpected-Stretagy-in-RL"><span class="toc-number">1.1.1.</span> <span class="toc-text">Unusual &amp; Unexpected Stretagy in RL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Supervised-Learning-as-Reinforcement-Learning"><span class="toc-number">1.1.2.</span> <span class="toc-text">Supervised Learning as Reinforcement Learning?</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Exploitation-Exploration-Dilema"><span class="toc-number">1.2.</span> <span class="toc-text">Exploitation-Exploration Dilema</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Elements-of-Reinforcement-Learning"><span class="toc-number">1.3.</span> <span class="toc-text">Elements of Reinforcement Learning</span></a></li></ol></li></ol>
                </div>
            
        
        
            <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Reinforcement Learning이란, 무엇을 할지에 대해 학습하는 것이다. 다르게 말하면, 어떤 상황이 입력으로 들어가서 어떤 액션이 출력되는 함수를 학습하는 것이다.</p>
<p>Reinforcement learning에선, 두 가지 중요한 특징이 있는데, 다음과 같다.</p>
<ul>
<li>Trails &amp; erros search</li>
<li>Delayed rewards</li>
</ul>
<p>물론 그 전에 environment를 인지할 수 있는 센서가 있어서 상황을 바탕으로 위 두 가지 특징이 발현된다.</p>
<h2 id="Overview-of-Reinforcement-Learning"><a href="#Overview-of-Reinforcement-Learning" class="headerlink" title="Overview of Reinforcement Learning"></a>Overview of Reinforcement Learning</h2><p>Supervised learning과 unsupervised learning은 다음과 같은 특성을 지닌다.</p>
<ul>
<li>숫자로된 테이블 형태의 데이터가 존재한다. ($X: N × D$$, $$Y: N × 1$) 이 두가지 데이터를 모두 넣고 모델을 학습하게 된다.</li>
<li>Static한 학습만 가능하다. 데이터를 추가하려면, 기존 데이터도 모두 넣고 fine-tuning 해야 하는 경우가 많다. 따라서, online-learning에 매우 불리하다.</li>
<li>시간이라는 개념이 없다(Sequence라는 개념은 있어도…). 그저 $X$를 받으면 $Y$를 줄 뿐. </li>
<li>Supervised learning의 경우, $Y$$가 $$X$ 동시에 주어지기에, 즉각적인 피드백이 있다.</li>
</ul>
<p>반면, reinforcement learning은 다음과 같은 차이점이 있다.</p>
<ul>
<li>데이터가 매우 비정형적이다. 로봇의 경우, environment로부터 받은 카메라 정보와 여라가지 센서 정보나 environment representation 정보 등이 있을 수 있다.</li>
<li>Dynamic하게 학습한다. Reinforcement learning은 데이터를 모아서 데이터셋을 만들어서 학습하는 형태가 아니라, environment에서 action을 취한 결과 피드백을 얻고 학습하는 형태이다. 즉, 그 자체가 그냥 online learning이다.</li>
<li>어떤 액션을 취하면 즉각적인 피드백이 없을 수 있고, 게임이 끝날 때 까지 피드백을 얻지 못할 수도 있다. 따라서, 상대적으로 시간이라는 개념이 존재한다. 즉, 액션과 리워드가 동시에 주어지지 않고 중간에 일정 시간이 있을 수 있다.</li>
</ul>
<h3 id="Unusual-amp-Unexpected-Stretagy-in-RL"><a href="#Unusual-amp-Unexpected-Stretagy-in-RL" class="headerlink" title="Unusual &amp; Unexpected Stretagy in RL"></a>Unusual &amp; Unexpected Stretagy in RL</h3><p>Reinforcement learning은 최종 value를 최대화하면서 학습한다. 그리고, 최종 value를 가장 높게 하는 방법을 알아서 찾아나가는데, 이때, 그 방법이 소위 말해서 수단과 방법을 가리지 않는 방법일 수  있다. 또한, agent가 취하는 액션은 나중에 보면 최대 reward를 받는 방법이었다는 것이 드러나지만, 액션 하나하나를 보면 인간이 전혀 이해하지 못하는 방향의 액션일 수도 있다.</p>
<h3 id="Supervised-Learning-as-Reinforcement-Learning"><a href="#Supervised-Learning-as-Reinforcement-Learning" class="headerlink" title="Supervised Learning as Reinforcement Learning?"></a>Supervised Learning as Reinforcement Learning?</h3><p>액션을 취하고 리워드를 얻는다는 것은 어떻게 보면 supervised learning과 연관지을 수도 있을 것이다. Environment가 $X$가 되고 그에 적절한 optimal action이 $Y$가 되는 것이다.</p>
<p>하지만, supervised learning을 쓰지 않고 reinforcement learning을 쓰는 이유가 있다.</p>
<ul>
<li>계산 불가능할 정도로 많은 environment/state 경우의 수</li>
<li>Supervised learning은 $X$와 $Y$를 동시에 필요로 하지만, $Y$가 있긴 한데, $X$ 동시에 주지 못하는 경우가 있다. 이때는 supervised learning을 할 수 없다.</li>
</ul>
<h2 id="Exploitation-Exploration-Dilema"><a href="#Exploitation-Exploration-Dilema" class="headerlink" title="Exploitation-Exploration Dilema"></a>Exploitation-Exploration Dilema</h2><p>Reinforcement learning에서의 agent는 최대한 많은 reward를 얻으면서 문제를 해결해야 한다. 이미 알고 있는 문제 해결 방법중에서 가장 큰 reward를 얻을 수 있는 방법을 선택해서 문제를 해결하는 것이 합리적일 것이다(exploitation). 그러나, agent는 새로운 길을 탐색해 나가면서 더 나은 길을 찾을 필요가 있다(exploration). 하지만, exploration과정은 많은 비용이 들 수도 있고 탐험 결과가 좋은 reward를 주는 경로가 아닐 수도 있다. 그럼에도 exploration은 필요하다.</p>
<ul>
<li><p>Exploitation</p>
<p>이미 찾은 문제 해결 방법중에서 가장 나은 방법을 선택하는 것. 즉, 최대 reward를 찾아가는 것.</p>
</li>
<li><p>Exploration</p>
<p>새로운 길을 탐색하는 것. 많은 비용이 들지만, 새로운 길이 지금까지 가지고 있었던 해결 방법들 보다 더 나은 reward를 줄 수도 있다.</p>
</li>
</ul>
<p>Exploration은 많은 비용이 들기 때문에, 당장은 reward를 얻지 못할 수도 있다. Exploitation을 하면 당장은 많은 reward를 얻을 수 있다. 이를 exploitaiton-exploration dilema라고 부른다.</p>
<h2 id="Elements-of-Reinforcement-Learning"><a href="#Elements-of-Reinforcement-Learning" class="headerlink" title="Elements of Reinforcement Learning"></a>Elements of Reinforcement Learning</h2><p>크게 4가지로 나눌 수 있다.</p>
<ul>
<li><p>Policy</p>
<p>어떤 주어진 환경/상황에서 어떤 동작을 취해야 하는지에 대한 규칙 또는 정책, 또는 매핑 함수이다. RL에서 핵심 역할을 하며, 단순한 매핑 테이블일수도, 아주 복잡한 함수나 확률적인 모델일 수도 있다.</p>
</li>
<li><p>Reward signal</p>
<p>액션에 대한 결과적인 상황에 따라 agent가 어떤 reward를 받을지에 대한, 즉, 시스템의 목표를 어떻게 할 것인지에 대한 것이다.</p>
</li>
<li><p>Value</p>
<p>Reward는 액션마다 주어질 수 있는 것으로, 이것만 있으면 greedy하게 갈 수 있다. 이를 방지하기 위해 reward를 누적하고 시스템 전체의 reward를 바라볼 수 있게 하는 것이 value이다. 즉, 어떤 state $s_{i}$에 대한 value $value(s_i)$는 그 상태 이후, 미래의 상태들 $s_{i+1}, s_{i+2},…$로부터 얻을 수 있는 reward 기댓값이다. 즉, $\text{argmax} ~ value(s)$라 함은, 당장 greedy한 선택이 아니라, 미래에 총 reward가 높은 방향으로 액션을 선택할 수 있게 해 준다.</p>
<p>value-function은 당장 앞에 놓인 action에 대해 value를 계산해주는 함수?</p>
<p>Reinforcement learning의 주요 task는 이 value function을 추정하는 것이다. agent는 value function이 가장 높은 value를 리턴해주는 액션을 선택하면 되니까.</p>
</li>
<li><p>Model of environment</p>
<p>Agent가 상호작용하는 환경을 정의한 것.</p>
</li>
</ul>
<p>이외에, episode라는 것이 있다. episode란, agent가 게임을 시작하고 끝날 때 까지의 기간, 즉, 한 게임을 의미한다. 다만, 게임같이 “한 게임”이라는 개념이 존재하는 episodic task가 있는 반면(바둑, 스타크래프트), “한 게임”을 정의할 수 없는, continuous task도 존재한다(로봇은 수명이 다할 때 까지 끊임없이 환경과 통신함). 이 경우에는 episode가 없다.</p>
<p>Reinforcement learning은 궁극적으로 reward를 최대화하는 것이지만, agent는 어떤 상황에서 높은 reward를 고르는게 아니라 value가 높은 쪽을 골라야 한다.</p>
<p>이 value function을 정의하는 방법은 두 가지가 있을 수 있다.</p>
<ul>
<li><p>Tabular solution method</p>
<p>Value function은 deterministic하다. 보통 deterministic한 함수들은 입력과 출력 매핑을 테이블 형태로 표현가능하다. 따라서, deterministic한 방법을 tabular method라고 부른다.</p>
<ul>
<li>Markov Decision Process</li>
</ul>
</li>
<li><p>Approximate solution method</p>
<p>Value function은 확률적이다.</p>
</li>
</ul>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/studynotes/reinforcement-learning/02-K-arm-Bandits-Problems/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">다음 글</strong>
            <div class="article-nav-title">
                
                    02. K-arm Bandits Problems
                
            </div>
        </a>
    
    
        <a href="/wiki/studynotes/machine-learning/Lagrangian-Multiplication/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">이전 글</strong>
            <div class="article-nav-title">Lagrangian Multiplication</div>
        </a>
    
</nav>





    
    

    <script src="https://utteranc.es/client.js"
        repo="taeuk-gang/taeuk-gang.github.io"
        issue-term="title"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>



<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            Lee Jaeyoung &copy; 2020 
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <!-- <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a> -->
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>